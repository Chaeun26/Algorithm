{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_ResNet_Simplified_ver.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "93ebbca061c74e6bbe846692d5d3e0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_69af34aeda204625afacae49a481c25a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ecffe9a291004a68b1a408939be8cde1",
              "IPY_MODEL_3c6e4a096a7a4582a962301bb9bb5182",
              "IPY_MODEL_4b9d328f55c44e40b667ffefd64dfa82"
            ]
          }
        },
        "69af34aeda204625afacae49a481c25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecffe9a291004a68b1a408939be8cde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a74a8f79ddab4c7b9f09615f0c6dc54a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03078169d10644fa9b111947e9c9ac03"
          }
        },
        "3c6e4a096a7a4582a962301bb9bb5182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_67fa474591cb4c008a5a174124dd1e15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c30b599b7b04c2e8e18475e3027cf10"
          }
        },
        "4b9d328f55c44e40b667ffefd64dfa82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f31d87acecd4fa0b1d0bb87dd33dcaa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 49912736.38it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58210fe8749448159460f98358d5125c"
          }
        },
        "a74a8f79ddab4c7b9f09615f0c6dc54a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03078169d10644fa9b111947e9c9ac03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67fa474591cb4c008a5a174124dd1e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c30b599b7b04c2e8e18475e3027cf10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f31d87acecd4fa0b1d0bb87dd33dcaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58210fe8749448159460f98358d5125c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaeun26/Algorithm/blob/main/CIFAR10_ResNet_Simplified_ver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TInvh8PrhfbB"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "# Those are for calculating errors.\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hep1BsNAiKg2"
      },
      "source": [
        "# BasicBlock for ResNet (simplified version) \n",
        "# -> they are connected to make ResNet construction\n",
        "\n",
        "# do each planes in the block\n",
        "# make block (without bottleneck architecture)\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        # to execute nn.Module.__init__()\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # use 3x3 filter(kernel) \n",
        "        # (change stride value to reduce width and height)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        # batch normalization for each planes (dimensions)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        # use 3x3 filter(kernel) (width and height are not changed because stride is 1)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes) # batch normalization\n",
        "\n",
        "        # nn.Sequential() is for small model\n",
        "        self.shortcut = nn.Sequential() \n",
        "        \n",
        "        # other option: identity mapping\n",
        "        # if it is not an Identity mapping, do projection\n",
        "        if stride != 1: \n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    # forward propagation\n",
        "    def forward(self, x):\n",
        "        # convolution - batch normalization - relu\n",
        "        out = F.relu(self.bn1(self.conv1(x))) \n",
        "        # 2nd convolution - batch normalization\n",
        "        out = self.bn2(self.conv2(out)) \n",
        "        # skip connection (x mapping)\n",
        "        out += self.shortcut(x) \n",
        "        # relu\n",
        "        out = F.relu(out) \n",
        "        return out\n",
        "\n",
        "# define ResNet class\n",
        "# based on ImageNet architecture\n",
        "# CIFAR10: (less parameter than ImageNet)\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        \n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        # change dimension using convolution\n",
        "        # input channel = 3 (R, G, B)\n",
        "        # output channel = 64 (change dimension)\n",
        "        # 3x3 filters (64 = # of filters)\n",
        "        # calcaulate output size = (input_size(image size) - filter size + 2xpadding)/stride + 1\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False) \n",
        "        # batch normalization to additional channel dimension (64)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        # (# of filters, # of blocks each layer, stride)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1) \n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2) \n",
        "        # linear transformation for fully connected layer\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        # the next strides are all 1, reduce width and height by the only first convolution\n",
        "        # downsampling through the stride 2 (halve feature map size) & double # of filter\n",
        "        # see the paper p.3. Plain Network part\n",
        "        strides = [stride] + [1] * (num_blocks - 1) \n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            # append blocks within the same layer\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            # change the number of input channels for the next block within the same layer\n",
        "            self.in_planes = planes \n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x))) # input, (+1 to # layer)\n",
        "\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "\n",
        "        # average pooling\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "\n",
        "        # use view to change the shape & applies linear transformation\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out) # fully-connected layer (+1 to # layer)\n",
        "        return out\n",
        "\n",
        "\n",
        "# define ResNet18 funtion (20 layers, n=3 for 6n+2)\n",
        "def ResNet18():\n",
        "    # each basic blocks (each column means the number of blocks) are overlapped twice\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2]) \n",
        "\n",
        "# define ResNet34 funtion (32 layers, n=5 for 6n+2)\n",
        "def ResNet34():\n",
        "    # each basic blocks are overlapped twice\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3]) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "93ebbca061c74e6bbe846692d5d3e0c1",
            "69af34aeda204625afacae49a481c25a",
            "ecffe9a291004a68b1a408939be8cde1",
            "3c6e4a096a7a4582a962301bb9bb5182",
            "4b9d328f55c44e40b667ffefd64dfa82",
            "a74a8f79ddab4c7b9f09615f0c6dc54a",
            "03078169d10644fa9b111947e9c9ac03",
            "67fa474591cb4c008a5a174124dd1e15",
            "3c30b599b7b04c2e8e18475e3027cf10",
            "9f31d87acecd4fa0b1d0bb87dd33dcaa",
            "58210fe8749448159460f98358d5125c"
          ]
        },
        "id": "jDLs2EHriRR9",
        "outputId": "f4869bc4-8a2a-412b-c223-d3b5d3811fc7"
      },
      "source": [
        "# download dataset (without normalization)\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    # training CIFAR10: padding=4, random crop with size 32                                  \n",
        "    transforms.RandomCrop(32, padding=4), \n",
        "    transforms.RandomHorizontalFlip(), # data augumentation\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "])\n",
        "\n",
        "# evaluate the single view of the original 32x32 image\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "])\n",
        "\n",
        "# using CIFAR10 provided by torchvision (download)\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# create loader objects\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93ebbca061c74e6bbe846692d5d3e0c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ0kah8-iWMB"
      },
      "source": [
        "device = 'cuda'\n",
        "\n",
        "# which ResNet do you want to use (change net!)\n",
        "net = ResNet34()\n",
        "net = net.to(device)\n",
        "# can we delete it?\n",
        "net = torch.nn.DataParallel(net)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "learning_rate = 0.1\n",
        "# save model file\n",
        "file_name = 'resnet18_cifar10.pt' \n",
        "\n",
        "# choose which loss to use & which optimizer to use\n",
        "# nn.CrossEntropyLoss(): useful for classification with C classes\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "# use the same one with the referenced one to compare\n",
        "def evaluate(model, data_loader, device):\n",
        "    \"\"\"\n",
        "    Calculate classification error (%) for given model\n",
        "    and data set.\n",
        "\n",
        "    by comparing the true y value and predicted value based on the model\n",
        "    \n",
        "    Parameters:\n",
        "    \n",
        "    - model: A Trained Pytorch Model \n",
        "    - data_loader: A Pytorch data loader object\n",
        "    \"\"\"\n",
        "    \n",
        "    y_true = np.array([], dtype=np.int)\n",
        "    y_pred = np.array([], dtype=np.int)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            y_true = np.concatenate((y_true, labels.cpu()))\n",
        "            y_pred = np.concatenate((y_pred, predicted.cpu()))\n",
        "    \n",
        "    error = np.sum(y_pred != y_true) / len(y_true)\n",
        "    return error\n",
        "\n",
        "def train(epoch):\n",
        "    print('\\n[ Train epoch: %d ]' % epoch)\n",
        "    net.train()\n",
        "    # variables to print process\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # load data through the train_loader with the specific batch size\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader): \n",
        "        \n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        # update model(ResNet) parameter for every epoach, every iteration\n",
        "        # through the back propagation (5 lines below)\n",
        "\n",
        "        # add gradients when backward propagation (in Pytorch)\n",
        "        # set all gradients to 0 before back propagation (after each iteration)\n",
        "        # if not, gradients can direct the different direction\n",
        "        optimizer.zero_grad() \n",
        "        # predicted data (made from the designed model)\n",
        "        pred = net(inputs)\n",
        "        # calculate loss \n",
        "        loss = criterion(pred, targets)\n",
        "        # backpropagation \n",
        "        loss.backward()\n",
        "        # update weight (the whole model parameter)\n",
        "        optimizer.step()\n",
        "        # print the loss value (training process)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # calculate accuracy\n",
        "        _, predicted = pred.max(1)\n",
        "\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('\\nCurrent batch:', str(batch_idx))\n",
        "            print('Current benign train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
        "            print('Current benign train loss:', loss.item())\n",
        "\n",
        "    train_error = evaluate(net, train_loader, device)\n",
        "\n",
        "    print('\\nTotal benign train accuarcy:', 100. * correct / total)\n",
        "    print('Total benign train loss:', train_loss)\n",
        "    print('Train error:', train_error)\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    print('\\n[ Test epoch: %d ]' % epoch)\n",
        "    # change network into evaluation mode (do not update a parameter)\n",
        "    net.eval() \n",
        "    # variables to print process (initialized)\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        total += targets.size(0)\n",
        "\n",
        "        # find output value from the input value\n",
        "        outputs = net(inputs) \n",
        "\n",
        "        # calculate loss\n",
        "        loss += criterion(outputs, targets).item()\n",
        "\n",
        "        # calculate accuracy\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    test_error = evaluate(net, test_loader, device)\n",
        "\n",
        "    print('\\nTest accuarcy:', 100. * correct / total)\n",
        "    print('Test average loss:', loss / total)\n",
        "    print('Test error:', test_error)\n",
        "\n",
        "    state = {\n",
        "        'net': net.state_dict()\n",
        "    }\n",
        "    if not os.path.isdir('checkpoint'):\n",
        "        os.mkdir('checkpoint')\n",
        "    torch.save(state, './checkpoint/' + file_name)\n",
        "    print('Model Saved!')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmkSBUFpicwJ",
        "outputId": "e2d20982-8be2-468a-ff07-9599e28f5d0e"
      },
      "source": [
        "# for epoch in range(0, 40)\n",
        "for epoch in range(0, 40):\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[ Train epoch: 0 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.1015625\n",
            "Current benign train loss: 2.426790714263916\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.2578125\n",
            "Current benign train loss: 2.041116714477539\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.2734375\n",
            "Current benign train loss: 1.9775303602218628\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.375\n",
            "Current benign train loss: 1.7740352153778076\n",
            "\n",
            "Total benign train accuarcy: 27.152\n",
            "Total benign train loss: 804.1382712125778\n",
            "Train error: 0.61156\n",
            "\n",
            "[ Test epoch: 0 ]\n",
            "\n",
            "Test accuarcy: 40.37\n",
            "Test average loss: 0.01628780416250229\n",
            "Test error: 0.5963\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 1 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.421875\n",
            "Current benign train loss: 1.6428111791610718\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.453125\n",
            "Current benign train loss: 1.5901762247085571\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.4921875\n",
            "Current benign train loss: 1.5169438123703003\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.4765625\n",
            "Current benign train loss: 1.4466947317123413\n",
            "\n",
            "Total benign train accuarcy: 43.282\n",
            "Total benign train loss: 600.4036689996719\n",
            "Train error: 0.5062\n",
            "\n",
            "[ Test epoch: 1 ]\n",
            "\n",
            "Test accuarcy: 50.62\n",
            "Test average loss: 0.013238091397285462\n",
            "Test error: 0.4938\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 2 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.5\n",
            "Current benign train loss: 1.425521731376648\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.4921875\n",
            "Current benign train loss: 1.2460559606552124\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.5546875\n",
            "Current benign train loss: 1.1681444644927979\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.5546875\n",
            "Current benign train loss: 1.1870217323303223\n",
            "\n",
            "Total benign train accuarcy: 53.494\n",
            "Total benign train loss: 502.1923961043358\n",
            "Train error: 0.42502\n",
            "\n",
            "[ Test epoch: 2 ]\n",
            "\n",
            "Test accuarcy: 58.73\n",
            "Test average loss: 0.01176865914463997\n",
            "Test error: 0.4127\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 3 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.578125\n",
            "Current benign train loss: 1.230225682258606\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.609375\n",
            "Current benign train loss: 1.1733378171920776\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.578125\n",
            "Current benign train loss: 1.1536957025527954\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.640625\n",
            "Current benign train loss: 1.050244688987732\n",
            "\n",
            "Total benign train accuarcy: 62.328\n",
            "Total benign train loss: 412.7376216650009\n",
            "Train error: 0.33612\n",
            "\n",
            "[ Test epoch: 3 ]\n",
            "\n",
            "Test accuarcy: 66.49\n",
            "Test average loss: 0.009473328405618667\n",
            "Test error: 0.3351\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 4 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.703125\n",
            "Current benign train loss: 1.0313175916671753\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.6484375\n",
            "Current benign train loss: 1.024343729019165\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.6875\n",
            "Current benign train loss: 0.7518662810325623\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.734375\n",
            "Current benign train loss: 0.800719678401947\n",
            "\n",
            "Total benign train accuarcy: 68.128\n",
            "Total benign train loss: 352.48354864120483\n",
            "Train error: 0.28386\n",
            "\n",
            "[ Test epoch: 4 ]\n",
            "\n",
            "Test accuarcy: 71.68\n",
            "Test average loss: 0.008074828165769578\n",
            "Test error: 0.2832\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 5 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.65625\n",
            "Current benign train loss: 0.9404223561286926\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.6953125\n",
            "Current benign train loss: 0.8374459743499756\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.6796875\n",
            "Current benign train loss: 0.9484153389930725\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.734375\n",
            "Current benign train loss: 0.7254185080528259\n",
            "\n",
            "Total benign train accuarcy: 73.006\n",
            "Total benign train loss: 301.464696764946\n",
            "Train error: 0.23656\n",
            "\n",
            "[ Test epoch: 5 ]\n",
            "\n",
            "Test accuarcy: 75.78\n",
            "Test average loss: 0.00692400529384613\n",
            "Test error: 0.2422\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 6 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.71875\n",
            "Current benign train loss: 0.8099758625030518\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.78125\n",
            "Current benign train loss: 0.6411770582199097\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.734375\n",
            "Current benign train loss: 0.7644714713096619\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.7734375\n",
            "Current benign train loss: 0.6846193671226501\n",
            "\n",
            "Total benign train accuarcy: 76.586\n",
            "Total benign train loss: 261.14870485663414\n",
            "Train error: 0.21264\n",
            "\n",
            "[ Test epoch: 6 ]\n",
            "\n",
            "Test accuarcy: 78.62\n",
            "Test average loss: 0.006197921711206436\n",
            "Test error: 0.2138\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 7 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.7890625\n",
            "Current benign train loss: 0.5362483859062195\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.71875\n",
            "Current benign train loss: 0.7486575841903687\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.8125\n",
            "Current benign train loss: 0.584621787071228\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.8046875\n",
            "Current benign train loss: 0.49140793085098267\n",
            "\n",
            "Total benign train accuarcy: 79.304\n",
            "Total benign train loss: 232.7345896065235\n",
            "Train error: 0.19432\n",
            "\n",
            "[ Test epoch: 7 ]\n",
            "\n",
            "Test accuarcy: 79.91\n",
            "Test average loss: 0.0058393886297941205\n",
            "Test error: 0.2009\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 8 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.8515625\n",
            "Current benign train loss: 0.5083968043327332\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.828125\n",
            "Current benign train loss: 0.5568565726280212\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.7421875\n",
            "Current benign train loss: 0.6697049736976624\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.8046875\n",
            "Current benign train loss: 0.4823293685913086\n",
            "\n",
            "Total benign train accuarcy: 81.332\n",
            "Total benign train loss: 211.18445819616318\n",
            "Train error: 0.16384\n",
            "\n",
            "[ Test epoch: 8 ]\n",
            "\n",
            "Test accuarcy: 82.51\n",
            "Test average loss: 0.005185501691699028\n",
            "Test error: 0.1749\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 9 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.84375\n",
            "Current benign train loss: 0.47464719414711\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.7890625\n",
            "Current benign train loss: 0.5586926937103271\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.859375\n",
            "Current benign train loss: 0.3841039836406708\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.828125\n",
            "Current benign train loss: 0.4491616189479828\n",
            "\n",
            "Total benign train accuarcy: 82.996\n",
            "Total benign train loss: 194.36861151456833\n",
            "Train error: 0.16886\n",
            "\n",
            "[ Test epoch: 9 ]\n",
            "\n",
            "Test accuarcy: 81.83\n",
            "Test average loss: 0.005354754030704499\n",
            "Test error: 0.1817\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 10 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.8359375\n",
            "Current benign train loss: 0.44139692187309265\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.84375\n",
            "Current benign train loss: 0.39795389771461487\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.44214871525764465\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.31621649861335754\n",
            "\n",
            "Total benign train accuarcy: 84.382\n",
            "Total benign train loss: 178.03806547820568\n",
            "Train error: 0.14488\n",
            "\n",
            "[ Test epoch: 10 ]\n",
            "\n",
            "Test accuarcy: 84.92\n",
            "Test average loss: 0.0046444779306650166\n",
            "Test error: 0.1508\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 11 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.35858845710754395\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.859375\n",
            "Current benign train loss: 0.32684817910194397\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.8828125\n",
            "Current benign train loss: 0.3512071967124939\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.84375\n",
            "Current benign train loss: 0.3928096294403076\n",
            "\n",
            "Total benign train accuarcy: 85.488\n",
            "Total benign train loss: 163.83089883625507\n",
            "Train error: 0.13194\n",
            "\n",
            "[ Test epoch: 11 ]\n",
            "\n",
            "Test accuarcy: 84.43\n",
            "Test average loss: 0.004585721279680729\n",
            "Test error: 0.1557\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 12 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9140625\n",
            "Current benign train loss: 0.25468680262565613\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.84375\n",
            "Current benign train loss: 0.4436713457107544\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.8203125\n",
            "Current benign train loss: 0.5136411786079407\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.8671875\n",
            "Current benign train loss: 0.43587714433670044\n",
            "\n",
            "Total benign train accuarcy: 86.352\n",
            "Total benign train loss: 153.46238972246647\n",
            "Train error: 0.12414\n",
            "\n",
            "[ Test epoch: 12 ]\n",
            "\n",
            "Test accuarcy: 85.93\n",
            "Test average loss: 0.004249487422406674\n",
            "Test error: 0.1407\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 13 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.828125\n",
            "Current benign train loss: 0.4825137257575989\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.8671875\n",
            "Current benign train loss: 0.3593311011791229\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.8828125\n",
            "Current benign train loss: 0.33513182401657104\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.3515472412109375\n",
            "\n",
            "Total benign train accuarcy: 87.396\n",
            "Total benign train loss: 141.9582259953022\n",
            "Train error: 0.11444\n",
            "\n",
            "[ Test epoch: 13 ]\n",
            "\n",
            "Test accuarcy: 86.49\n",
            "Test average loss: 0.004033030876517296\n",
            "Test error: 0.1351\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 14 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.8671875\n",
            "Current benign train loss: 0.37784600257873535\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.37035179138183594\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.3007882237434387\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.90625\n",
            "Current benign train loss: 0.356587678194046\n",
            "\n",
            "Total benign train accuarcy: 88.168\n",
            "Total benign train loss: 132.80669549107552\n",
            "Train error: 0.10718\n",
            "\n",
            "[ Test epoch: 14 ]\n",
            "\n",
            "Test accuarcy: 86.14\n",
            "Test average loss: 0.003976437391340733\n",
            "Test error: 0.1386\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 15 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9375\n",
            "Current benign train loss: 0.26547884941101074\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.875\n",
            "Current benign train loss: 0.37725135684013367\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.921875\n",
            "Current benign train loss: 0.311078816652298\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.3011987805366516\n",
            "\n",
            "Total benign train accuarcy: 88.49\n",
            "Total benign train loss: 129.02783553302288\n",
            "Train error: 0.10574\n",
            "\n",
            "[ Test epoch: 15 ]\n",
            "\n",
            "Test accuarcy: 86.67\n",
            "Test average loss: 0.003962965987622738\n",
            "Test error: 0.1333\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 16 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.8359375\n",
            "Current benign train loss: 0.39510756731033325\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.29295817017555237\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.90625\n",
            "Current benign train loss: 0.33437007665634155\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.2728863060474396\n",
            "\n",
            "Total benign train accuarcy: 89.24\n",
            "Total benign train loss: 120.55547013878822\n",
            "Train error: 0.09424\n",
            "\n",
            "[ Test epoch: 16 ]\n",
            "\n",
            "Test accuarcy: 87.52\n",
            "Test average loss: 0.0037436200231313705\n",
            "Test error: 0.1248\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 17 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.8828125\n",
            "Current benign train loss: 0.3295072317123413\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.875\n",
            "Current benign train loss: 0.31177040934562683\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9140625\n",
            "Current benign train loss: 0.24688313901424408\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.8984375\n",
            "Current benign train loss: 0.3180951774120331\n",
            "\n",
            "Total benign train accuarcy: 90.074\n",
            "Total benign train loss: 112.44654279202223\n",
            "Train error: 0.09036\n",
            "\n",
            "[ Test epoch: 17 ]\n",
            "\n",
            "Test accuarcy: 87.99\n",
            "Test average loss: 0.003615582573413849\n",
            "Test error: 0.1201\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 18 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9375\n",
            "Current benign train loss: 0.22232280671596527\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.27519485354423523\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9375\n",
            "Current benign train loss: 0.1919190138578415\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9140625\n",
            "Current benign train loss: 0.22782862186431885\n",
            "\n",
            "Total benign train accuarcy: 90.608\n",
            "Total benign train loss: 105.38356418907642\n",
            "Train error: 0.0883\n",
            "\n",
            "[ Test epoch: 18 ]\n",
            "\n",
            "Test accuarcy: 88.55\n",
            "Test average loss: 0.0035157894775271416\n",
            "Test error: 0.1145\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 19 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.8671875\n",
            "Current benign train loss: 0.3035006821155548\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.921875\n",
            "Current benign train loss: 0.20581597089767456\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.875\n",
            "Current benign train loss: 0.3409463167190552\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.90625\n",
            "Current benign train loss: 0.28918206691741943\n",
            "\n",
            "Total benign train accuarcy: 90.914\n",
            "Total benign train loss: 102.00144297629595\n",
            "Train error: 0.08402\n",
            "\n",
            "[ Test epoch: 19 ]\n",
            "\n",
            "Test accuarcy: 87.82\n",
            "Test average loss: 0.003605046936124563\n",
            "Test error: 0.1218\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 20 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.8984375\n",
            "Current benign train loss: 0.2724868953227997\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.2774171233177185\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.13982734084129333\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.84375\n",
            "Current benign train loss: 0.33827197551727295\n",
            "\n",
            "Total benign train accuarcy: 91.274\n",
            "Total benign train loss: 97.25685977190733\n",
            "Train error: 0.08042\n",
            "\n",
            "[ Test epoch: 20 ]\n",
            "\n",
            "Test accuarcy: 88.4\n",
            "Test average loss: 0.0036742337659001353\n",
            "Test error: 0.116\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 21 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9140625\n",
            "Current benign train loss: 0.2592896521091461\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.2349967509508133\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.8984375\n",
            "Current benign train loss: 0.23353984951972961\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.21547392010688782\n",
            "\n",
            "Total benign train accuarcy: 91.828\n",
            "Total benign train loss: 92.03593507409096\n",
            "Train error: 0.06894\n",
            "\n",
            "[ Test epoch: 21 ]\n",
            "\n",
            "Test accuarcy: 89.23\n",
            "Test average loss: 0.0032658478513360022\n",
            "Test error: 0.1077\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 22 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.16153110563755035\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.90625\n",
            "Current benign train loss: 0.27581506967544556\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.921875\n",
            "Current benign train loss: 0.2782287001609802\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.8984375\n",
            "Current benign train loss: 0.2760789692401886\n",
            "\n",
            "Total benign train accuarcy: 92.204\n",
            "Total benign train loss: 88.35964232683182\n",
            "Train error: 0.06698\n",
            "\n",
            "[ Test epoch: 22 ]\n",
            "\n",
            "Test accuarcy: 89.32\n",
            "Test average loss: 0.003273832429945469\n",
            "Test error: 0.1068\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 23 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.32461580634117126\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9140625\n",
            "Current benign train loss: 0.19222934544086456\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.921875\n",
            "Current benign train loss: 0.21857011318206787\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.8984375\n",
            "Current benign train loss: 0.31968826055526733\n",
            "\n",
            "Total benign train accuarcy: 92.444\n",
            "Total benign train loss: 84.07022162526846\n",
            "Train error: 0.07732\n",
            "\n",
            "[ Test epoch: 23 ]\n",
            "\n",
            "Test accuarcy: 88.22\n",
            "Test average loss: 0.003711984506249428\n",
            "Test error: 0.1178\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 24 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.8828125\n",
            "Current benign train loss: 0.2729513943195343\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.8984375\n",
            "Current benign train loss: 0.24425776302814484\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.279211163520813\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.1469125598669052\n",
            "\n",
            "Total benign train accuarcy: 92.72\n",
            "Total benign train loss: 81.40408188849688\n",
            "Train error: 0.06666\n",
            "\n",
            "[ Test epoch: 24 ]\n",
            "\n",
            "Test accuarcy: 89.22\n",
            "Test average loss: 0.0033696882501244546\n",
            "Test error: 0.1078\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 25 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.921875\n",
            "Current benign train loss: 0.2146310806274414\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9140625\n",
            "Current benign train loss: 0.26328393816947937\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9375\n",
            "Current benign train loss: 0.16865761578083038\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9375\n",
            "Current benign train loss: 0.17270922660827637\n",
            "\n",
            "Total benign train accuarcy: 93.06\n",
            "Total benign train loss: 78.38694570958614\n",
            "Train error: 0.06606\n",
            "\n",
            "[ Test epoch: 25 ]\n",
            "\n",
            "Test accuarcy: 89.05\n",
            "Test average loss: 0.0035242341876029967\n",
            "Test error: 0.1095\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 26 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.16183693706989288\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9609375\n",
            "Current benign train loss: 0.11720608919858932\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.18772636353969574\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.14206562936306\n",
            "\n",
            "Total benign train accuarcy: 93.024\n",
            "Total benign train loss: 77.68413805216551\n",
            "Train error: 0.0589\n",
            "\n",
            "[ Test epoch: 26 ]\n",
            "\n",
            "Test accuarcy: 89.97\n",
            "Test average loss: 0.003200994573533535\n",
            "Test error: 0.1003\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 27 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.16353380680084229\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.921875\n",
            "Current benign train loss: 0.18426565825939178\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.90625\n",
            "Current benign train loss: 0.25760966539382935\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.2117498517036438\n",
            "\n",
            "Total benign train accuarcy: 93.254\n",
            "Total benign train loss: 75.40981806069613\n",
            "Train error: 0.05798\n",
            "\n",
            "[ Test epoch: 27 ]\n",
            "\n",
            "Test accuarcy: 90.24\n",
            "Test average loss: 0.003226825837045908\n",
            "Test error: 0.0976\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 28 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.15934886038303375\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.07423563301563263\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.1877545565366745\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.11566852033138275\n",
            "\n",
            "Total benign train accuarcy: 93.642\n",
            "Total benign train loss: 71.0263349339366\n",
            "Train error: 0.0576\n",
            "\n",
            "[ Test epoch: 28 ]\n",
            "\n",
            "Test accuarcy: 89.42\n",
            "Test average loss: 0.0033067782618105414\n",
            "Test error: 0.1058\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 29 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9140625\n",
            "Current benign train loss: 0.22172699868679047\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.13338404893875122\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.12580250203609467\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.1553288996219635\n",
            "\n",
            "Total benign train accuarcy: 93.718\n",
            "Total benign train loss: 68.17019622027874\n",
            "Train error: 0.05244\n",
            "\n",
            "[ Test epoch: 29 ]\n",
            "\n",
            "Test accuarcy: 89.58\n",
            "Test average loss: 0.003348830632865429\n",
            "Test error: 0.1042\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 30 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.20271509885787964\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.18325603008270264\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.90625\n",
            "Current benign train loss: 0.2303575575351715\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.15460442006587982\n",
            "\n",
            "Total benign train accuarcy: 94.194\n",
            "Total benign train loss: 66.15805482119322\n",
            "Train error: 0.053\n",
            "\n",
            "[ Test epoch: 30 ]\n",
            "\n",
            "Test accuarcy: 89.93\n",
            "Test average loss: 0.003177681701630354\n",
            "Test error: 0.1007\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 31 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.1279463917016983\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.18513700366020203\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9609375\n",
            "Current benign train loss: 0.12202288955450058\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9375\n",
            "Current benign train loss: 0.20443396270275116\n",
            "\n",
            "Total benign train accuarcy: 94.206\n",
            "Total benign train loss: 63.60086654871702\n",
            "Train error: 0.04992\n",
            "\n",
            "[ Test epoch: 31 ]\n",
            "\n",
            "Test accuarcy: 90.15\n",
            "Test average loss: 0.0031711122512817383\n",
            "Test error: 0.0985\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 32 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.14292733371257782\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.875\n",
            "Current benign train loss: 0.2791614234447479\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9609375\n",
            "Current benign train loss: 0.11154921352863312\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9609375\n",
            "Current benign train loss: 0.08570942282676697\n",
            "\n",
            "Total benign train accuarcy: 94.296\n",
            "Total benign train loss: 63.55476403608918\n",
            "Train error: 0.05526\n",
            "\n",
            "[ Test epoch: 32 ]\n",
            "\n",
            "Test accuarcy: 89.91\n",
            "Test average loss: 0.003387733297049999\n",
            "Test error: 0.1009\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 33 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9375\n",
            "Current benign train loss: 0.15524020791053772\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9140625\n",
            "Current benign train loss: 0.19991429150104523\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.921875\n",
            "Current benign train loss: 0.19545438885688782\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9140625\n",
            "Current benign train loss: 0.21056102216243744\n",
            "\n",
            "Total benign train accuarcy: 94.292\n",
            "Total benign train loss: 63.32279637828469\n",
            "Train error: 0.05554\n",
            "\n",
            "[ Test epoch: 33 ]\n",
            "\n",
            "Test accuarcy: 89.89\n",
            "Test average loss: 0.003237946727126837\n",
            "Test error: 0.1011\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 34 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.24522660672664642\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.14988654851913452\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.14733456075191498\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.921875\n",
            "Current benign train loss: 0.18764649331569672\n",
            "\n",
            "Total benign train accuarcy: 94.652\n",
            "Total benign train loss: 59.614142928272486\n",
            "Train error: 0.05068\n",
            "\n",
            "[ Test epoch: 34 ]\n",
            "\n",
            "Test accuarcy: 90.07\n",
            "Test average loss: 0.0031699574127793313\n",
            "Test error: 0.0993\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 35 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9375\n",
            "Current benign train loss: 0.1659369319677353\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.21180056035518646\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.1119263619184494\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.921875\n",
            "Current benign train loss: 0.2809440493583679\n",
            "\n",
            "Total benign train accuarcy: 94.614\n",
            "Total benign train loss: 59.969093542546034\n",
            "Train error: 0.05294\n",
            "\n",
            "[ Test epoch: 35 ]\n",
            "\n",
            "Test accuarcy: 90.17\n",
            "Test average loss: 0.0032198440939188\n",
            "Test error: 0.0983\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 36 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.1322142779827118\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.14437726140022278\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.1710028052330017\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.1778935343027115\n",
            "\n",
            "Total benign train accuarcy: 94.75\n",
            "Total benign train loss: 57.46261437237263\n",
            "Train error: 0.04284\n",
            "\n",
            "[ Test epoch: 36 ]\n",
            "\n",
            "Test accuarcy: 90.74\n",
            "Test average loss: 0.003080401582270861\n",
            "Test error: 0.0926\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 37 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9609375\n",
            "Current benign train loss: 0.1447056233882904\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.11079102009534836\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9375\n",
            "Current benign train loss: 0.2000245451927185\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.1536235809326172\n",
            "\n",
            "Total benign train accuarcy: 94.914\n",
            "Total benign train loss: 55.662248741835356\n",
            "Train error: 0.0437\n",
            "\n",
            "[ Test epoch: 37 ]\n",
            "\n",
            "Test accuarcy: 90.62\n",
            "Test average loss: 0.0030707525789737703\n",
            "Test error: 0.0938\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 38 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.16376936435699463\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.12634292244911194\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.890625\n",
            "Current benign train loss: 0.2917063534259796\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.11212921142578125\n",
            "\n",
            "Total benign train accuarcy: 95.198\n",
            "Total benign train loss: 53.79531406983733\n",
            "Train error: 0.04308\n",
            "\n",
            "[ Test epoch: 38 ]\n",
            "\n",
            "Test accuarcy: 90.52\n",
            "Test average loss: 0.003228961555659771\n",
            "Test error: 0.0948\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 39 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9140625\n",
            "Current benign train loss: 0.2149789035320282\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.96875\n",
            "Current benign train loss: 0.09453275054693222\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.0779135674238205\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.96875\n",
            "Current benign train loss: 0.1458001285791397\n",
            "\n",
            "Total benign train accuarcy: 95.258\n",
            "Total benign train loss: 53.33177511021495\n",
            "Train error: 0.03892\n",
            "\n",
            "[ Test epoch: 39 ]\n",
            "\n",
            "Test accuarcy: 91.43\n",
            "Test average loss: 0.0029301694355905058\n",
            "Test error: 0.0857\n",
            "Model Saved!\n"
          ]
        }
      ]
    }
  ]
}